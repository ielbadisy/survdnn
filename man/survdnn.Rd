% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/survdnn.R
\name{survdnn}
\alias{survdnn}
\title{Fit a Deep Neural Network for Survival Analysis}
\usage{
survdnn(
  formula,
  data,
  hidden = c(32L, 16L),
  activation = "relu",
  lr = 1e-04,
  epochs = 300L,
  loss = c("cox", "cox_l2", "aft", "coxtime"),
  verbose = TRUE,
  dropout = 0.3,
  batch_norm = TRUE,
  callbacks = NULL,
  .seed = NULL,
  .device = c("auto", "cpu", "cuda")
)
}
\arguments{
\item{formula}{A survival formula of the form `Surv(time, status) ~ predictors`.}

\item{data}{A data frame containing the variables in the model.}

\item{hidden}{Integer vector. Sizes of the hidden layers (default: c(32, 16)).}

\item{activation}{Character string specifying the activation function.}

\item{lr}{Learning rate for the Adam optimizer (default: `1e-4`).}

\item{epochs}{Number of training epochs (default: 300).}

\item{loss}{Character name of the loss function to use. One of `"cox"`,
`"cox_l2"`, `"aft"`, or `"coxtime"`.}

\item{verbose}{Logical; whether to print loss progress every 50 epochs.}

\item{dropout}{Numeric between 0 and 1. Dropout rate applied after each
hidden layer (default = 0.3). Set to 0 to disable dropout.}

\item{batch_norm}{Logical; whether to apply batch normalization after each
hidden layer (default = TRUE).}

\item{callbacks}{Optional list of callback functions to control training
(e.g., early stopping).}

\item{.seed}{Optional integer for full reproducibility.}

\item{.device}{Character string: `"auto"`, `"cpu"`, or `"cuda"`.}
}
\value{
A `survdnn` model object.
}
\description{
Trains a deep neural network (DNN) to model right-censored survival data.
}

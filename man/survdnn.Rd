% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/survdnn.R
\name{survdnn}
\alias{survdnn}
\title{Fit a Deep Neural Network for Survival Analysis}
\usage{
survdnn(
  formula,
  data,
  hidden = c(32L, 16L),
  activation = "relu",
  lr = 1e-04,
  epochs = 300L,
  .loss_fn = cox_loss,
  verbose = TRUE
)
}
\arguments{
\item{formula}{A survival formula of the form `Surv(time, status) ~ predictors`.}

\item{data}{A data.frame containing the variables in the model.}

\item{hidden}{Integer vector. Sizes of the hidden layers (default: c(32, 16)).}

\item{activation}{Character string specifying the activation function to use in each layer.
Supported: `"relu"`, `"leaky_relu"`, `"tanh"`, `"sigmoid"`, `"gelu"`, `"elu"`, `"softplus"`.}

\item{lr}{Learning rate for the Adam optimizer (default: `1e-4`).}

\item{epochs}{Number of training epochs (default: 300).}

\item{.loss_fn}{A custom loss function compatible with torch (default: `cox_loss`).}

\item{verbose}{Logical; whether to print loss progress every 50 epochs (default: TRUE).}
}
\value{
An object of class `"survdnn"` containing:
\describe{
  \item{model}{Trained `nn_module` object.}
  \item{formula}{Original survival formula.}
  \item{data}{Training data used for fitting.}
  \item{xnames}{Predictor variable names.}
  \item{x_center}{Column means of predictors.}
  \item{x_scale}{Column standard deviations of predictors.}
  \item{loss}{Final epoch loss.}
  \item{loss_history}{Vector of loss values per epoch.}
  \item{activation}{Used activation function.}
  \item{hidden}{Hidden layer sizes.}
  \item{lr}{Learning rate used.}
  \item{epochs}{Number of training epochs.}
  \item{.loss_fn}{The loss function used for training.}
  \item{loss_name}{Character representation of the loss function name.}
}
}
\description{
Trains a flexible deep neural network (DNN) to model right-censored survival data
using the specified loss function. Supports Cox loss and any custom `torch`-compatible loss.
}
\examples{
set.seed(123)
n <- 100
x1 <- rnorm(n)
x2 <- rbinom(n, 1, 0.5)
time <- rexp(n, rate = 0.1)
status <- rbinom(n, 1, 0.7)
df <- data.frame(time = time, status = status, x1 = x1, x2 = x2)

mod <- survdnn(Surv(time, status) ~ ., data = df, epochs = 50, verbose = FALSE)
mod$loss  # final training loss
}
